\documentclass[12pt,usletter,english]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage[font={small}]{caption}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{listings}

\pagestyle{fancy}
\lhead{Problem Set 1} \rhead{Deepthi Gorthi}

\begin{document}
\title{PS1: Introduction to Probablity and Statistics} \author{Deepthi Gorthi\\ AY250: Stellar Populations} \maketitle

\noindent \textbf{Problem 1.} \\ 

(a) In 1995, they introduced blue M\&M's.  Before then, the color mix in a bag of plain M\&M's was 30\% brown, 20\% yellow, 20\% red, 10\% green, 10\% orange, and 10\% tan.  Afterward, it was 24\% blue, 20\% green, 16\% orange, 14\% yellow, 13\% red, 13\% brown.

Suppose there are two bags of M\&M's, one from 1994 and one from 1996 and you are randomly given one M\&M from each bag.  One is yellow, one is green.  Using Bayes's theorem and a probability table to determine the \underline{relative} probability that the yellow M\&M came from the 1994 bag. \\

(b) Evaluate the ``Evidence'' and determine the \underline{normalized} probability that the yellow M\&M came from the 1994 bag. \\

\noindent \textit{Hint: This is similar to how we wrote out the Monty Hall problem in class.} \\

\noindent \textbf{Solution:} \\

(a) The given distribution of M\&M's can be summarized as follows:
%% +------+-----+-----+
%% |Colour|1994 |1996 |
%% +------+-----+-----+
%% |Brown |0.3  |0.13 |
%% +------+-----+-----+
%% |Yellow|0.2  |0.14 |
%% +------+-----+-----+
%% |Red   |0.2  |0.13 |
%% +------+-----+-----+
%% |Green |0.1  |0.2  |
%% +------+-----+-----+
%% |Orange|0.1  |0.16 |
%% +------+-----+-----+
%% |      |0.1  |0.24 |
%% +------+-----+-----+

\begin{center}
\label{tab:mm}
\begin{tabular}{|l|l|l|}
\hline
Colour & 1994 & 1996 \\
\hline
Brown & 0.3 & 0.13 \\
\hline
Yellow & 0.2 & 0.14 \\
\hline
Red & 0.2 & 0.13 \\
\hline
Green & 0.1 & 0.2 \\
\hline
Orange & 0.1 & 0.16 \\
\hline
Other & 0.1 & 0.24 \\
\hline
\end{tabular}
\end{center}

Given data: One M\&M was drawn from each sample and one of them is
yellow and another green. To evaluate the relative probablity that the
yellow M\&M was drawn from the 1994 bag (and hence the green from the
1996 bag), define the two hypothesis as:

\noindent$H_1$: The yellow M\&M is drawn from the 1994 bag and the green M\&M from the
1996 bag.
\noindent$H_2$: The yellow M\&M is drawn from the 1996 bag and the green M\&M from the
1994 bag.

Since we have no prior knowledge about either hypothesis, we should
begin with flat priors- either hypothesis is equally likely. For
probability of the data given the hypothesis we can multiply the
probabilities of drawing the green and yellow M\&Ms from the
respective bag, since they are independent events.
%% +----------+-------+------------+-----------+
%% |Hypothesis|P(H)   |P(D|H)      |P(D|H)*P(H)|
%% |          |       |            |           |
%% +----------+-------+------------+-----------+
%% |$H_1$     |1/2    |(0.2)*(0.2) |0.02       |
%% |          |       |            |           |
%% +----------+-------+------------+-----------+
%% |$H_2$     |1/2    |(0.14)*(0.1)|0.007      |
%% |          |       |            |           |
%% +----------+-------+------------+-----------+

\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
Hypothesis & P(H) & P(D$|$H) & P(D$|$H)*P(H) \\
 & & & \\
\hline
$H_1$ & 1/2 & (0.2)*(0.2) & 0.02 \\
 & & & \\
\hline
$H_2$ & 1/2 & (0.14)*(0.1) & 0.007 \\
 & & & \\
\hline
\end{tabular}
\end{center}

The relative probability that the yellow M\&M was drawn from the 1994
bag is \fbox{0.02}.\\

\noindent(b) The `evidence' is also the probability of the data given all the
possible hypotheses. This can be obtained by summing over the
likelihoods of all the hypotheses.
\begin{equation}
  P(D) = 0.02+0.007 = 0.027
\end{equation}

\noindent Hence the normalized probability that the yellow M\&M came from the
1994 bag is:

\begin{equation}
  P(H_1|D) = \frac{P(D|H_1)*P(H_1)}{P(D)} = \frac{0.02}{0.027} \sim 74\%
\end{equation}

The normalized probability of our hypothesis that the yellow M\&M was
drawn from the 1994 bag is \fbox{74\%}.



\noindent \textbf{Problem 2.} \\ 

Using notes from class, code up your own Metropolis-Hastings (M-H)
MCMC sampler.  Although it is technically impossible to prove that an
MCMC sampler definitively converges (this would require infinite
runtime), a simple sanity test it is to sample from a one dimensional
Gaussian distribution:
\begin{equation}
P(x)= \frac{1}{\sqrt{2\pi\sigma^2}} e^\frac{-(\mu-x)^2}{2\sigma^2}
\end{equation}

\noindent where $\mu$ and $\sigma$ are values you choose, and $x$
values are generated by your M-H sampler.  The density of samples
should trace the input distribution.  For example, if you select
$\mu=5$ and $\sigma=1$, the density of samples for $x$ should be a 1d
Gaussian with these values (perhaps modulo a normalization
constant). Make plots that qualitatively demonstrate convergence of
your sampler to a steady state (e.g., lnP vs. $x$, lnP vs. step
number) and a plot that shows your samples relative to the true
distribution. Your choice in step size should yield an acceptance
fraction between $\sim$0.25 and 0.5. \\

\noindent \textbf{Solution}\\

The Metropolis-Hastings Algorithm that I wrote up to sample the given
gaussian is included in the same folder as mcmc_sampler.py


\end{document}
